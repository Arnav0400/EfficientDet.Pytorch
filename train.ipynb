{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from models.efficientdet import EfficientDet\n",
    "from models.losses import FocalLoss\n",
    "from datasets import Spine_dataset, get_augumentation, detection_collate\n",
    "from utils import EFFICIENTDET\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = None\n",
    "network = 'efficientdet-d0'\n",
    "num_epochs = 100\n",
    "batch_size = 2\n",
    "num_worker = 4\n",
    "num_classes = 1\n",
    "device = [0]\n",
    "grad_accumulation_steps = 1\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "gamma = 0.1\n",
    "save_folder = 'weights/'\n",
    "image_root = 'boostnet_labeldata/data/'\n",
    "csv_root = 'boostnet_labeldata/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_device(device):\n",
    "    n_gpu_use = len(device)\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    if n_gpu_use > 0 and n_gpu == 0:\n",
    "        print(\"Warning: There\\'s no GPU available on this machine, training will be performed on CPU.\")\n",
    "        n_gpu_use = 0\n",
    "    if n_gpu_use > n_gpu:\n",
    "        print(\"Warning: The number of GPU\\'s configured to use is {}, but only {} are available on this machine.\".format(\n",
    "            n_gpu_use, n_gpu))\n",
    "        n_gpu_use = n_gpu\n",
    "    list_ids = device\n",
    "    device = torch.device('cuda:{}'.format(\n",
    "        device[0]) if n_gpu_use > 0 else 'cpu')\n",
    "\n",
    "    return device, list_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_dict(model):\n",
    "    if type(model) == torch.nn.DataParallel:\n",
    "        state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        state_dict = model.state_dict()\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "if(resume is not None):\n",
    "    resume_path = str(resume)\n",
    "    print(\"Loading checkpoint: {} ...\".format(resume_path))\n",
    "    checkpoint = torch.load(\n",
    "        resume, map_location=lambda storage, loc: storage)\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    network = checkpoint['network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_df_train = pd.read_csv(csv_root+'training/landmarks.csv',header = None)\n",
    "filename_df_train = pd.read_csv(csv_root+'training/filenames.csv',header = None)\n",
    "boxes_df_train = pd.read_csv(csv_root+'training/train.csv')\n",
    "boxes_df_train.label = 0 # All boxes same class??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_df_test = pd.read_csv(csv_root+'test/landmarks.csv',header = None)\n",
    "filename_df_test = pd.read_csv(csv_root+'test/filenames.csv',header = None)\n",
    "boxes_df_test = pd.read_csv(csv_root+'test/test.csv')\n",
    "boxes_df_test.label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Spine_dataset.SPINEDetection(image_root,boxes_df_train,corner_df_train,filename_df_train,transform=get_augumentation('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Spine_dataset.SPINEDetection(image_root,boxes_df_test,corner_df_test,filename_df_test,transform=get_augumentation('test'),image_set='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_worker,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=detection_collate,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_worker,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=detection_collate,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2, 3, 1408, 768]) torch.Size([2, 17, 5]) torch.Size([2, 17, 8])\n"
     ]
    }
   ],
   "source": [
    "for idx, (images, annotations, corners) in enumerate(train_dataloader):\n",
    "    print(idx ,images.shape, annotations.shape, corners.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientDet(num_classes=num_classes,\n",
    "                     network=network,\n",
    "                     W_bifpn=EFFICIENTDET[network]['W_bifpn'],\n",
    "                     D_bifpn=EFFICIENTDET[network]['D_bifpn'],\n",
    "                     D_class=EFFICIENTDET[network]['D_class'],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(resume is not None):\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "device, device_ids = prepare_device(device)\n",
    "model = model.to(device)\n",
    "if(len(device_ids) > 1):\n",
    "    model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=3, verbose=True)\n",
    "criterion = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch: \t start training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17f6a47a8e8477a82d89aec83b71b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    time           : 127.09938168525696\n",
      "    loss           : 61446.87183123703\n",
      "    corner_loss    : 61440.595016289546\n",
      "    bbox_loss      : 1.797781619046239\n",
      "    cls_loss       : 4.479049701413673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffda7d58747345f48669ec401d3d13c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/naamii-server2/EfficientDet.Pytorch/datasets/Spine_dataset.py\", line 41, in __getitem__\n    augmentation = self.transform(**annotation)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/core/composition.py\", line 174, in __call__\n    p.preprocess(data)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/core/utils.py\", line 63, in preprocess\n    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction=\"to\")\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/core/utils.py\", line 71, in check_and_convert\n    return self.convert_to_albumentations(data, rows, cols)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 51, in convert_to_albumentations\n    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in convert_bboxes_to_albumentations\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in <listcomp>\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 251, in convert_bbox_to_albumentations\n    check_bbox(bbox)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 330, in check_bbox\n    \"to be in the range [0.0, 1.0], got {value}.\".format(bbox=bbox, name=name, value=value)\nValueError: Expected x_max for bbox (0.6532399299474606, 0.4307944307944308, 1.0035026269702276, 0.49221949221949224, 0) to be in the range [0.0, 1.0], got 1.0035026269702276.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-04dffcf057c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtotal_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_corners\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mannotations_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations_bboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/naamii-server2/EfficientDet.Pytorch/datasets/Spine_dataset.py\", line 41, in __getitem__\n    augmentation = self.transform(**annotation)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/core/composition.py\", line 174, in __call__\n    p.preprocess(data)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/core/utils.py\", line 63, in preprocess\n    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction=\"to\")\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/core/utils.py\", line 71, in check_and_convert\n    return self.convert_to_albumentations(data, rows, cols)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 51, in convert_to_albumentations\n    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in convert_bboxes_to_albumentations\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 303, in <listcomp>\n    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 251, in convert_bbox_to_albumentations\n    check_bbox(bbox)\n  File \"/home/naamii-server2/anaconda3/envs/deeplearning-pytorch/lib/python3.7/site-packages/albumentations/augmentations/bbox_utils.py\", line 330, in check_bbox\n    \"to be in the range [0.0, 1.0], got {value}.\".format(bbox=bbox, name=name, value=value)\nValueError: Expected x_max for bbox (0.6532399299474606, 0.4307944307944308, 1.0035026269702276, 0.49221949221949224, 0) to be in the range [0.0, 1.0], got 1.0035026269702276.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"{} epoch: \\t start training....\".format(epoch))\n",
    "    \n",
    "    start = time.time()\n",
    "    result = {}\n",
    "    total_loss = []\n",
    "    corner_losses = []\n",
    "    bbox_losses = []\n",
    "    cls_losses = []\n",
    "    optimizer.zero_grad()\n",
    "    total_batches = len(train_dataloader)\n",
    "    tk0 = tqdm(train_dataloader, total=total_batches)\n",
    "    for idx, (images, annotations_bboxes, annotations_corners) in enumerate(tk0):\n",
    "        images = images.to(device)\n",
    "        annotations_bboxes = annotations_bboxes.to(device)\n",
    "        annotations_corners = annotations_corners.to(device)\n",
    "        classification, regression, corners, anchors = model(images)\n",
    "        classification_loss, regression_loss, corner_loss= criterion(\n",
    "            classification, regression, corners, anchors, annotations_bboxes, annotations_corners)\n",
    "        classification_loss = classification_loss.mean()\n",
    "        regression_loss = regression_loss.mean()\n",
    "        corner_loss = corner_loss.mean()\n",
    "        loss = classification_loss + regression_loss + corner_loss\n",
    "        if bool(loss == 0):\n",
    "            print('loss equal zero(0)')\n",
    "            continue\n",
    "        loss.backward()\n",
    "        if (idx+1) % grad_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        total_loss.append(loss.item())\n",
    "        corner_losses.append(corner_loss.item())\n",
    "        bbox_losses.append(regression_loss.item())\n",
    "        cls_losses.append(classification_loss.item())\n",
    "        tk0.set_postfix(loss=(np.mean(total_loss)))\n",
    "    result = {\n",
    "        'time': time.time() - start,\n",
    "        'loss': np.mean(total_loss),\n",
    "        'corner_loss': np.mean(corner_losses),\n",
    "        'bbox_loss': np.mean(bbox_losses),\n",
    "        'cls_loss': np.mean(cls_losses)\n",
    "    }\n",
    "    for key, value in result.items():\n",
    "        print('    {:15s}: {}'.format(str(key), value)) \n",
    "        \n",
    "    start = time.time()\n",
    "    result = {}\n",
    "    total_loss = []\n",
    "    corner_losses = []\n",
    "    bbox_losses = []\n",
    "    cls_losses = []\n",
    "    optimizer.zero_grad()\n",
    "    total_batches = len(test_dataloader)\n",
    "    tk0 = tqdm(test_dataloader, total=total_batches)\n",
    "    for idx, (images, annotations_bboxes, annotations_corners) in enumerate(tk0):\n",
    "        images = images.to(device)\n",
    "        annotations_bboxes = annotations_bboxes.to(device)\n",
    "        annotations_corners = annotations_corners.to(device)\n",
    "        classification, regression, corners, anchors = model(images)\n",
    "        classification_loss, regression_loss, corner_loss= criterion(\n",
    "            classification, regression, corners, anchors, annotations_bboxes, annotations_corners)\n",
    "        classification_loss = classification_loss.mean()\n",
    "        regression_loss = regression_loss.mean()\n",
    "        corner_loss = corner_loss.mean()\n",
    "        loss = classification_loss + regression_loss + corner_loss\n",
    "        if bool(loss == 0):\n",
    "            print('loss equal zero(0)')\n",
    "            continue\n",
    "        loss.backward()\n",
    "        if (idx+1) % grad_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        total_loss.append(loss.item())\n",
    "        corner_losses.append(corner_loss.item())\n",
    "        bbox_losses.append(regression_loss.item())\n",
    "        cls_losses.append(classification_loss.item())\n",
    "        tk0.set_postfix(loss=(np.mean(total_loss)))\n",
    "    result = {\n",
    "        'time': time.time() - start,\n",
    "        'loss': np.mean(total_loss),\n",
    "        'corner_loss': np.mean(corner_losses),\n",
    "        'bbox_loss': np.mean(bbox_losses),\n",
    "        'cls_loss': np.mean(cls_losses)\n",
    "    }\n",
    "    for key, value in result.items():\n",
    "        print('    {:15s}: {}'.format(str(key), value))\n",
    "    scheduler.step(np.mean(total_loss))\n",
    "\n",
    "    arch = type(model).__name__\n",
    "    state = {\n",
    "        'arch': arch,\n",
    "        'num_class': num_classes,\n",
    "        'network': network,\n",
    "        'state_dict': get_state_dict(model)\n",
    "    }\n",
    "    torch.save(\n",
    "        state, './weights/checkpoint_{}_{}.pth'.format(network, epoch))\n",
    "state = {\n",
    "    'arch': arch,\n",
    "    'num_class': num_classes,\n",
    "    'network': network,\n",
    "    'state_dict': get_state_dict(model)\n",
    "}\n",
    "torch.save(state, './weights/Final_{}.pth'.format(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
